{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f88d82e-4054-4608-9909-fb7fedff69e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Script ---\n",
      "‚úÖ Loaded input file: dataset - Copy.xlsx\n",
      "‚ÑπÔ∏è Existing output file found. Will resume progress.\n",
      "‚û°Ô∏è  Row 1/100 already processed. Skipping.\n",
      "‚û°Ô∏è  Row 2/100 already processed. Skipping.\n",
      "‚û°Ô∏è  Row 3/100 already processed. Skipping.\n",
      "‚û°Ô∏è  Row 4/100 already processed. Skipping.\n",
      "‚û°Ô∏è  Row 5/100 already processed. Skipping.\n",
      "‚û°Ô∏è  Row 6/100 already processed. Skipping.\n",
      "‚û°Ô∏è  Row 7/100 already processed. Skipping.\n",
      "‚û°Ô∏è  Row 8/100 already processed. Skipping.\n",
      "‚û°Ô∏è  Row 9/100 already processed. Skipping.\n",
      "‚û°Ô∏è  Row 10/100 already processed. Skipping.\n",
      "‚öôÔ∏è  Processing row 11/100...\n"
     ]
    },
    {
     "ename": "RateLimitException",
     "evalue": "API rate limit reached. Details: 'Rate limit exceeded: free-models-per-day. Add 10 credits to unlock 1000 free model requests per day'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRateLimitException\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 151\u001b[0m\n\u001b[0;32m    148\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWrite a short and simple Python code for: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquestion\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚öôÔ∏è  Processing row \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_rows\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 151\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mcall_llm_api\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    153\u001b[0m df_to_process\u001b[38;5;241m.\u001b[39mat[idx, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mResult Answer from LLM\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manswer\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    154\u001b[0m df_to_process\u001b[38;5;241m.\u001b[39mat[idx, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput Tokens\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_tokens\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "Cell \u001b[1;32mIn[14], line 65\u001b[0m, in \u001b[0;36mcall_llm_api\u001b[1;34m(prompt)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m429\u001b[39m:\n\u001b[0;32m     64\u001b[0m     error_details \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m'\u001b[39m, {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo details provided.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RateLimitException(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAPI rate limit reached. Details: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror_details\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m408\u001b[39m, \u001b[38;5;241m500\u001b[39m, \u001b[38;5;241m502\u001b[39m, \u001b[38;5;241m503\u001b[39m, \u001b[38;5;241m504\u001b[39m]:\n\u001b[0;32m     68\u001b[0m     error_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAPI Error (Code \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mreason\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mRateLimitException\u001b[0m: API rate limit reached. Details: 'Rate limit exceeded: free-models-per-day. Add 10 credits to unlock 1000 free model requests per day'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import requests\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "\n",
    "# ---------------------------------------------\n",
    "# CONFIGURATION - Change these values as needed\n",
    "# ---------------------------------------------\n",
    "# API details\n",
    "API_KEY = \"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\"\n",
    "API_URL = \"https://openrouter.ai/api/v1/chat/completions\"\n",
    "MODEL_NAME = \"moonshotai/kimi-dev-72b:free\"\n",
    "\n",
    "# Input/Output file names\n",
    "input_excel_path = 'dataset - Copy.xlsx'\n",
    "output_excel_path = 'kimi_dev_72b_results.xlsx'\n",
    "\n",
    "# Sheet to process\n",
    "sheet_to_process = 'allenai lila _ 100'\n",
    "\n",
    "# How often to save progress (e.g., every 5 rows)\n",
    "checkpoint_every = 5\n",
    "\n",
    "# Delay between *successful* API calls in seconds\n",
    "sleep_time = 1.5\n",
    "\n",
    "# --- (NEW) Retry Configuration for API Failures ---\n",
    "MAX_RETRIES = 4  # Max number of retries for a single request\n",
    "INITIAL_RETRY_DELAY = 5  # Initial delay in seconds for the first retry\n",
    "# ---------------------------------------------\n",
    "\n",
    "# --- Custom Exception for Rate Limiting ---\n",
    "class RateLimitException(Exception):\n",
    "    \"\"\"Custom exception for handling API rate limit errors.\"\"\"\n",
    "    pass\n",
    "\n",
    "# --- (MODIFIED) Function to call LLM API with Retry Logic ---\n",
    "def call_llm_api(prompt):\n",
    "    \"\"\"\n",
    "    Sends a prompt to the LLM API and returns the response.\n",
    "    Includes retry logic with exponential backoff for transient errors.\n",
    "    \"\"\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {API_KEY}\"\n",
    "    }\n",
    "    data = {\n",
    "        \"model\": MODEL_NAME,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant designed to solve math problems. Provide a clear, step-by-step solution and state the final answer.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    last_error = None\n",
    "    for attempt in range(MAX_RETRIES):\n",
    "        start_time = time.time()\n",
    "        try:\n",
    "            response = requests.post(API_URL, headers=headers, json=data, timeout=90)\n",
    "            latency = time.time() - start_time\n",
    "\n",
    "            # --- SUCCESS ---\n",
    "            if response.status_code == 200:\n",
    "                res_json = response.json()\n",
    "                answer = res_json['choices'][0]['message']['content']\n",
    "                usage = res_json.get('usage', {})\n",
    "                return {\n",
    "                    \"answer\": answer,\n",
    "                    \"input_tokens\": usage.get('prompt_tokens', 0),\n",
    "                    \"output_tokens\": usage.get('completion_tokens', 0),\n",
    "                    \"total_tokens\": usage.get('total_tokens', 0),\n",
    "                    \"latency\": latency\n",
    "                }\n",
    "\n",
    "            # --- FATAL: RATE LIMITING ---\n",
    "            elif response.status_code == 429:\n",
    "                error_details = response.json().get('error', {}).get('message', 'No details provided.')\n",
    "                raise RateLimitException(f\"API rate limit reached. Details: '{error_details}'\")\n",
    "\n",
    "            # --- RETRYABLE ERRORS (Server-side issues) ---\n",
    "            elif response.status_code in [408, 500, 502, 503, 504]:\n",
    "                error_text = f\"API Error (Code {response.status_code}): {response.reason}\"\n",
    "                print(f\"   ‚ö†Ô∏è  {error_text}. Will retry...\")\n",
    "                last_error = {\"answer\": error_text, \"input_tokens\": 0, \"output_tokens\": 0, \"total_tokens\": 0, \"latency\": latency}\n",
    "\n",
    "            # --- FATAL ERRORS (Client-side issues like bad auth or invalid request) ---\n",
    "            else:\n",
    "                error_text = response.json().get('error', {}).get('message', str(response.text))\n",
    "                final_error = f\"API Error (Code {response.status_code}): {error_text}\"\n",
    "                print(f\"   ‚ùå Unrecoverable {final_error}\")\n",
    "                return {\"answer\": final_error, \"input_tokens\": 0, \"output_tokens\": 0, \"total_tokens\": 0, \"latency\": latency}\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            latency = time.time() - start_time\n",
    "            print(f\"   ‚ö†Ô∏è  Network Error: {e}. Will retry...\")\n",
    "            last_error = {\"answer\": f\"Network Error: {e}\", \"input_tokens\": 0, \"output_tokens\": 0, \"total_tokens\": 0, \"latency\": latency}\n",
    "        \n",
    "        except requests.exceptions.JSONDecodeError as e:\n",
    "            latency = time.time() - start_time\n",
    "            print(f\"   ‚ö†Ô∏è  JSON Parse Error: {e}. Malformed response. Will retry...\")\n",
    "            last_error = {\"answer\": f\"JSON Parse Error: {response.text}\", \"input_tokens\": 0, \"output_tokens\": 0, \"total_tokens\": 0, \"latency\": latency}\n",
    "\n",
    "        # --- Exponential Backoff ---\n",
    "        # Don't sleep on the last attempt\n",
    "        if attempt < MAX_RETRIES - 1:\n",
    "            # e.g., 5s, 10s, 20s... + some randomness\n",
    "            backoff_time = INITIAL_RETRY_DELAY * (2 ** attempt) + random.uniform(0, 1)\n",
    "            print(f\"      -> Retrying in {backoff_time:.2f} seconds... (Attempt {attempt + 2}/{MAX_RETRIES})\")\n",
    "            time.sleep(backoff_time)\n",
    "        else:\n",
    "            print(f\"   ‚ùå Max retries reached. Failing permanently for this row.\")\n",
    "\n",
    "    # If all retries fail, return the last captured error\n",
    "    return last_error\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Main Processing Logic (No changes needed here)\n",
    "# ---------------------------------------------\n",
    "print(\"--- Starting Script ---\")\n",
    "\n",
    "# --- Create output directory if it doesn't exist ---\n",
    "output_dir = os.path.dirname(output_excel_path)\n",
    "if output_dir:\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    print(f\"‚úÖ Ensured output directory exists: '{output_dir}'\")\n",
    "\n",
    "# 1. Load input Excel file\n",
    "try:\n",
    "    xls = pd.ExcelFile(input_excel_path)\n",
    "    print(f\"‚úÖ Successfully loaded input file: '{input_excel_path}'\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ùå FATAL ERROR: Input file not found at '{input_excel_path}'. Exiting.\")\n",
    "    sys.exit()\n",
    "\n",
    "# 2. Check for existing output file to enable resuming\n",
    "output_xls = None\n",
    "if os.path.exists(output_excel_path):\n",
    "    try:\n",
    "        output_xls = pd.ExcelFile(output_excel_path)\n",
    "        print(f\"‚ÑπÔ∏è  Found existing output file. Will resume progress.\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Warning: Could not read existing output file '{output_excel_path}'. It might be corrupted. A new file will be created. Error: {e}\")\n",
    "\n",
    "# 3. Set up the ExcelWriter to save progress\n",
    "try:\n",
    "    writer_mode = 'a' if output_xls else 'w'\n",
    "    writer_kwargs = {\n",
    "        \"engine\": 'openpyxl',\n",
    "        \"mode\": writer_mode\n",
    "    }\n",
    "    if writer_mode == 'a':\n",
    "        writer_kwargs['if_sheet_exists'] = 'replace'\n",
    "\n",
    "    with pd.ExcelWriter(output_excel_path, **writer_kwargs) as writer:\n",
    "        print(f\"\\nüîÑ Processing sheet: '{sheet_to_process}'\")\n",
    "\n",
    "        if sheet_to_process not in xls.sheet_names:\n",
    "            print(f\"‚ùå FATAL ERROR: Sheet '{sheet_to_process}' not found in the input file. Exiting.\")\n",
    "            sys.exit()\n",
    "\n",
    "        df_to_process = pd.read_excel(xls, sheet_name=sheet_to_process)\n",
    "\n",
    "        # RESUME LOGIC\n",
    "        result_columns = ['Result Answer from LLM', 'Input Tokens', 'Output Tokens', 'Total Tokens', 'Latency (s)']\n",
    "        if output_xls and sheet_to_process in output_xls.sheet_names:\n",
    "            df_existing_output = pd.read_excel(output_xls, sheet_name=sheet_to_process)\n",
    "            print(\"   -> Merging existing results...\")\n",
    "            for col in result_columns:\n",
    "                if col in df_existing_output.columns:\n",
    "                    df_to_process[col] = df_existing_output.get(col)\n",
    "                else:\n",
    "                    df_to_process[col] = None\n",
    "        else:\n",
    "            for col in result_columns:\n",
    "                df_to_process[col] = None\n",
    "\n",
    "        df_to_process['Result Answer from LLM'] = df_to_process['Result Answer from LLM'].astype('object')\n",
    "\n",
    "        # --- Main Processing Loop ---\n",
    "        try:\n",
    "            total_rows = len(df_to_process)\n",
    "            for idx, row in df_to_process.iterrows():\n",
    "                if pd.notna(row.get('Result Answer from LLM')) and row.get('Result Answer from LLM') != \"\":\n",
    "                    print(f\"‚û°Ô∏è  Row {idx+1}/{total_rows} already processed. Skipping.\")\n",
    "                    continue\n",
    "\n",
    "                question = row.get('Questions', 'No question found in row')\n",
    "                options = row.get('Options', '')\n",
    "\n",
    "                if pd.isna(options) or options == '':\n",
    "                    prompt = f\"Solve this math problem: {question}\"\n",
    "                else:\n",
    "                    prompt = f\"Solve this math problem: {question}\\nOptions: {options}\"\n",
    "\n",
    "                print(f\"‚öôÔ∏è  Processing row {idx+1}/{total_rows}...\")\n",
    "                result = call_llm_api(prompt)\n",
    "\n",
    "                df_to_process.at[idx, 'Result Answer from LLM'] = result['answer']\n",
    "                df_to_process.at[idx, 'Input Tokens'] = result['input_tokens']\n",
    "                df_to_process.at[idx, 'Output Tokens'] = result['output_tokens']\n",
    "                df_to_process.at[idx, 'Total Tokens'] = result['total_tokens']\n",
    "                df_to_process.at[idx, 'Latency (s)'] = round(result['latency'], 2)\n",
    "\n",
    "                print(f\"‚úÖ Processed row {idx+1}/{total_rows} | Latency: {round(result['latency'], 2)}s\")\n",
    "\n",
    "                time.sleep(sleep_time)\n",
    "\n",
    "                if (idx + 1) % checkpoint_every == 0 or (idx + 1) == total_rows:\n",
    "                    df_to_process.to_excel(writer, sheet_name=sheet_to_process, index=False)\n",
    "                    print(f\"üíæ Checkpoint saved at row {idx+1}\")\n",
    "\n",
    "        except RateLimitException as e:\n",
    "            print(\"\\n\" + \"=\"*60)\n",
    "            print(\"üõë EXECUTION HALTED: API RATE LIMIT REACHED\")\n",
    "            print(f\"   Error Details: {e}\")\n",
    "            print(\"   Progress up to this point will be saved.\")\n",
    "            print(\"=\"*60)\n",
    "        except Exception as e:\n",
    "            print(f\"\\nAn unexpected error occurred during processing: {e}\")\n",
    "            print(\"Saving progress before exiting.\")\n",
    "\n",
    "        finally:\n",
    "            print(\"\\nSaving final progress...\")\n",
    "            df_to_process.to_excel(writer, sheet_name=sheet_to_process, index=False)\n",
    "            print(f\"‚úÖ Final data for sheet '{sheet_to_process}' saved.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå A critical error occurred with the Excel file writer: {e}\")\n",
    "    print(\"   Please ensure the output file is not open in another program and that you have permission to write to the folder.\")\n",
    "\n",
    "\n",
    "print(f\"\\nüéâ All operations finished. Results are saved in '{output_excel_path}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ebced2-e0f4-4962-b5d1-49bf733e237c",
   "metadata": {},
   "outputs": [],
   "source": [
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f4d18c-5c53-44fe-a599-b27616171c5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
